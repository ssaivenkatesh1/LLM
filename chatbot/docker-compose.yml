version: '3.8'
services:
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    volumes:
      - ./src:/app/src
    depends_on:
      - backend
      - chromadb
    env_file:
      - .env
    environment:
      - BACKEND_URL=${BACKEND_URL}

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "8001:8001"
    volumes:
      - ./backend:/app/backend
    env_file:
      - .env
    environment:
      # ðŸ§  Choose ONE setup â€” OpenAI or Google â€” depending on which provider you use.
      
      # ---- OpenAI Setup ----
      # - EMBEDDING_PROVIDER=openai
      # - LLM_PROVIDER=openai
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
      # ---- OR Google Gemini Setup ----
      # - EMBEDDING_PROVIDER=google
      # - LLM_PROVIDER=google
      # - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      # - GOOGLE_EMBEDDING_MODEL=models/embedding-001
      # - GOOGLE_LLM_MODEL=gemini-pro
      # ---- OR Ollama Setup ----
      - EMBEDDING_PROVIDER=ollama
      - LLM_PROVIDER=ollama
      - OLLAMA_MODEL=nomic-embed-text
      - OLLAMA_LLM_MODEL=llama2
      - OLLAMA_BASE_URL=http://host.docker.internal:11434

      - CHROMA_DB_HOST=${CHROMA_DB_HOST}
      - CHROMA_DB_PORT=${CHROMA_DB_PORT}


  chromadb:
    image: chromadb/chroma
    ports:
      - "8000:8000"